import os
import ember
import numpy as np
import tensorflow as tf


def init_vectorized_features(dataset_dir: str):
    """
    Required for the generation of '.dat' data files

    :param dataset_dir: directory to the base location of the dataset
    :return:
    """
    try:
        assert(os.path.exists(dataset_dir))

        ember.create_vectorized_features(dataset_dir, 1)
    except AssertionError:
        raise Exception(
            "[ASSERTION ERROR] The path to base directory of dataset provided does not exist"
        )


def dat_to_train_test(dat_dir: str):
    """
    Loading training & testing data from respective generated '.dat' files

    :param dat_dir: directory to the base location where generated '.dat' files are found
    :return:
    """
    try:
        assert('X_train.dat' in os.listdir(dat_dir))
        assert('y_train.dat' in os.listdir(dat_dir))
        assert ('X_test.dat' in os.listdir(dat_dir))
        assert ('y_test.dat' in os.listdir(dat_dir))

        x_train, y_train = ember.read_vectorized_features(dat_dir, subset="train")
        x_test, y_test = ember.read_vectorized_features(dat_dir, subset="test")

        return x_train, y_train, x_test, y_test
    except AssertionError:
        raise Exception(
            "[ASSERTION ERROR] Ensure that the required '.dat' files are found within the specified directory"
        )


def __dataset_generator(data: np.memmap, labels: np.memmap):
    """
    Helper function for conversion from numpy.memmap to tf.data.Dataset
    Create callable generator for tf.data.Dataset.from_generator()

    :param data: numpy.memmap of training data
    :param labels: numpy.memmap of labels corresponding to the training data
    :return:
    """
    # requires nothing to be passed to generator to avoid "TypeError: 'generator' must be callable." error
    def generator():
        for instance, label in zip(data, labels):
            yield instance, label
    return generator


def to_tf_dataset(x_memmap_data: np.memmap, y_memmap_data: np.memmap):
    """
    Convert numpy.memmap to tf.data.Dataset via the creation of generator with helper function '__dataset_generator()'

    :return:
    """
    return tf.data.Dataset.from_generator(__dataset_generator(x_memmap_data, y_memmap_data),
                                          output_types=(x_memmap_data.dtype, y_memmap_data.dtype),
                                          output_shapes=([x_memmap_data.shape[1], ], []))


def __unlabelled(data: tf.Tensor, label: tf.Tensor):
    """
    Helper function to act as a callable conditional statement for tf.data.Dataset.filter()

    Note: data is an unused parameter but is necessary for the proper functionality of this function
    (i.e. do not remove)

    :param data: tensor representation of data within the tf.data.Dataset
    :param label: tensor representation of label for the respective data within tf.data.Dataset
    :return:
    """
    if label == -1.0:
        return False
    return True


def rm_unlabelled_samples(dataset: tf.data.Dataset):
    """
    Filter all unlabelled data instances (label = -1.0) from the tf.data.Dataset passed in as parameter

    :param dataset: dataset in which the unlabelled instances (label = -1.0) are to be filtered out.
    :return:
    """
    return dataset.filter(__unlabelled)


def to_batch_dataset(dataset: tf.data.Dataset, batchsize: int = 100, drop_remainder: bool = False):
    """
    TODO write this
    TODO fill in parameter descriptions

    :param dataset:
    :param batchsize:
    :param drop_remainder:
    :return:
    """
    return dataset.batch(batchsize, drop_remainder)
