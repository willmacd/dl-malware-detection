import lightgbm
import matplotlib.pyplot as plt
from DataProcessing.LoadData import dat_to_train_test
import numpy as np


class LightGBM_Booster:
	def __init__(self):
		"""
		Constructor for LightGBM Booster Model

		"""

		# How to init?
		self.booster_model = []

	def train(self, dataset: lightgbm.basic.Dataset, num_iterations: int = 1000, learning_rate: float = 0.05,
			  num_leaves: int = 2048, max_depth: int = 15, min_data_in_leaf: int = 50, feature_fraction: float = 0.5):
		"""
		Training method for LightGBM Boosting model

		:param num_leaves: Number of leaves in a tree
		:param max_depth: Maximum depth of a decision tree
		:param min_data_in_leaf:
		:param feature_fraction:
		:param learning_rate: Learning rate for the model training
		:param num_iterations: Number of iterations/epochs
		:param dataset: lightGBM dataset object containing the training data
		:return:
		"""

		# Parameters for lightgbm take in a dict
		parameters = {
			"boosting": "gbdt",
			"objective": "binary",
			"num_iterations": num_iterations,
			"learning_rate": learning_rate,
			"num_leaves": num_leaves,
			"max_depth": max_depth,
			"min_data_in_leaf": min_data_in_leaf,
			"feature_fraction": feature_fraction}

		self.booster_model = lightgbm.train(train_set=dataset, params=parameters)
		self.booster_model.save_model('model.txt')

	def evaluate_dataset_accuracy(self, raw_data: np.array, raw_labels: np.array):
		"""

		:param model: LightGBM Booster model (Trained)
		:param raw_data: Raw data for the dataset for use in prediction
		:param raw_labels: Labels for the  dataset
		:return: Total correct predictions and length of dataset (For percentage)
		"""

		# Remove -1 from the dataset
		filtered_rows = (raw_labels != -1)
		filtered_data = raw_data[filtered_rows]

		predictions = self.booster_model.predict(filtered_data)

		# Convert to array
		prediction = np.array(predictions)

		# Convert to binary
		predictions_binary = np.where(prediction > 0.5, 1, 0)

		# Convert from Float memmap to int array
		labels_array = np.array(filtered_data.astype(int))

		predictions_binary = np.array(predictions_binary)
		print(len(predictions_binary))
		print(predictions_binary[0])
		print(filtered_data[0])
		print(len(filtered_data))
		print(labels_array)
		print(len(labels_array))

		np.savetxt("predictions.txt", predictions_binary)
		np.savetxt("labels.txt", labels_array)
		np.savetxt("filtered.txt", filtered_data)


		print(len(labels_array))
		count = 0
		for i in range(0, (len(labels_array)-2)):

			if predictions_binary[i] == labels_array[i]:
				count += 1

		print(count)
		return count, len(labels_array)

	def create_training_dataset(self, dataset_dir: str):
		"""
		Creates an object of type LightGBM dataset containing the data

		:param dataset_dir: Directory where the dataset is contained
		:return: LightGBM dataset representation of dataset
		"""

		# Get data
		x_train, y_train, x_test, y_test = dat_to_train_test(dataset_dir)

		# Remove -1 from the dataset
		filtered_rows = (y_train != -1)

		return lightgbm.Dataset(x_train[filtered_rows], y_train[filtered_rows])
