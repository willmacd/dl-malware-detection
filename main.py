import os
import tensorflow as tf
from DataProcessing.LoadData import dat_to_train_test, to_tf_dataset, \
    rm_unlabelled_samples, to_batch_dataset, normalize_data, dataset_pca_reduction
from Model.MalwareDetection import MalwareDetection

FILTERED_DATASET_SIZES = 600000

BATCH_SIZE = 1000
EPOCHS = 125

# CHECK: Ensure that this is the correct path to the dataset
DATA_DIR = './ember/'

if __name__ == '__main__':
    # Create the instance of the MalwareDetection model
    model = MalwareDetection()

    model.summary()

    x_train, y_train, x_test, y_test = dat_to_train_test(DATA_DIR)

    # Normalize the data using robust scaler
    x_train_scaled = normalize_data(x_train)
    x_test_scaled = normalize_data(x_test)

    # Apply PCA dimensionality reduction
    x_train_pca, x_test_pca = dataset_pca_reduction(x_train, x_test)

    # Number of components kept by PCA
    num_components_pca = len(x_train[1])
    print(num_components_pca)

    unfiltered_train_ds = to_tf_dataset(x_train_pca, y_train)
    unfiltered_test_ds = to_tf_dataset(x_test_pca, y_test)

    # Filter out the data with label '-1' (unlabeled)
    filtered_train_ds = rm_unlabelled_samples(unfiltered_train_ds)
    filtered_test_ds = rm_unlabelled_samples(unfiltered_test_ds)


    train_ds = filtered_train_ds.take(int(0.85 * FILTERED_DATASET_SIZES))
    val_ds = filtered_train_ds.skip(int(0.85 * FILTERED_DATASET_SIZES))
    test_ds = to_batch_dataset(filtered_test_ds, BATCH_SIZE)

    train_ds = to_batch_dataset(train_ds, BATCH_SIZE)
    val_ds = to_batch_dataset(val_ds, BATCH_SIZE)

    model.train(train_ds,
                validation_dataset=val_ds,
                epochs=EPOCHS,
                optimizer=tf.keras.optimizers.Adam,
                learning_rate=0.000125)

    test_loss, test_acc = model.test(test_ds)

    print(test_loss)
    print(test_acc)
